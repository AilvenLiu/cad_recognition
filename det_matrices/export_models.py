import sys
import torch
import torch.nn as nn
import torch.quantization
import argparse
from _utils.models import get_student_model
from _utils.datasets import get_data_loaders
from train_matrices import train_student



def load_class_mapping(class_map_path):
    with open(class_map_path, 'r') as f:
        return json.load(f)
    
def replace_relu6_with_relu(module):
    for name, sub_module in module.named_children():
        if isinstance(sub_module, nn.ReLU6):
            setattr(module, name, nn.ReLU(inplace=True))
        else:
            replace_relu6_with_relu(sub_module)

def generate_fusion_config(module, prefix=''):
    fuse_config = []
    for name, sub_module in module.named_children():
        full_name = prefix + ('.' if prefix else '') + name
        
        if isinstance(sub_module, nn.Sequential):
            layer_names = list(sub_module._modules.keys())
            for i in range(len(layer_names) - 2):
                if isinstance(sub_module._modules[layer_names[i]], nn.Conv2d) and \
                   isinstance(sub_module._modules[layer_names[i + 1]], nn.BatchNorm2d) and \
                   isinstance(sub_module._modules[layer_names[i + 2]], nn.ReLU):
                    fuse_config.append([f"{full_name}.{layer_names[i]}", f"{full_name}.{layer_names[i + 1]}", f"{full_name}.{layer_names[i + 2]}"])

        # Recursively handle nested modules
        fuse_config += generate_fusion_config(sub_module, full_name)
    
    return fuse_config


def train_quantized(device, init, margin, learning_rate, num_class, num_epochs, train_loader, val_loader, weight_path, threshold_path):
    writter = SummaryWriter(log_dir="/root/tf-logs/quantized")
    
    threshold_euc, threshold_cos = np.load(threshold_path+'_student.npz')['arr_0']
    print(f'\nThreshold generated by teacher: euc = {threshold_euc:.4f}, cosine = {threshold_cos:.4f}')
    
    model = get_student_model(num_classes=num_class, dropout_p=0.3, init=init, update=False, weight_path=weight_path, cuda=True).to(device)
    teacher = get_teacher_model(num_classes=num_class, dropout_p=0.3, init=False, update=False, weight_path=weight_path, cuda=True).to(device)
    
    criterion = get_loss(model=model, margin=margin, num_classes=num_class, num_epochs=None)
    
    base_optimizer = AdaBelief(model.parameters(), lr=learning_rate, weight_decay=1e-2, eps=1e-16, betas=(0.89, 0.999), weight_decouple=True, rectify=True)
    optimizer = Lookahead(base_optimizer, k=5, alpha=0.5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, min_lr=1e-8)
    
    scaler = GradScaler()
    best_val_loss = float('inf')
    best_score_cos = 0

    for epoch in range(num_epochs):
        epoch_loss = 0.0
        model.train()
        
        train_tqdm = tqdm(train_loader, desc=f"Train Epoch {epoch+1}/{num_epochs}")
        for (anchor_img, contrastive_img, positive_img, negative_img, 
             anchor_label, positive_label, negative_label) in train_tqdm:
            
            anchor_img, contrastive_img, positive_img, negative_img = anchor_img.to(device), contrastive_img.to(device), positive_img.to(device), negative_img.to(device)
            anchor_labels, positive_labels, negative_labels = anchor_label.to(device), positive_label.to(device), negative_label.to(device)
            
            optimizer.zero_grad()

            with autocast():
                anchor_features, anchor_logits = model(anchor_img)
                positive_features, positive_logits = model(positive_img)
                negative_features, negative_logits = model(negative_img)
                teacher_features, teacher_logits = teacher(anchor_img)
                
                loss = criterion(anchor_features, positive_features, negative_features, 
                                 anchor_logits, positive_logits, negative_logits, 
                                 anchor_labels, positive_labels, negative_labels, 
                                 None, teacher_logits, teacher_features )

            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            check_requires_grad(model)
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()
            train_tqdm.set_postfix(loss=loss.item())
        if epoch % 10 == 0:
            threshold_euc, threshold_cos = find_optimal_threshold(device, model, train_loader)
            print(f'\nThreshold found on train set: euclid = {threshold_euc}, cosine = {threshold_cos}')
            np.savez(threshold_path+'_quantized.npz', [threshold_euc, threshold_cos])
            
        avg_epoch_loss = epoch_loss / len(train_loader)
        torch.save(model.state_dict(), weight_path+"_quantized_last.pth")
        
        (
            val_loss, same_accuracy_euc, different_accuracy_euc, 
            same_class_accuracy_cos, different_class_accuracy_cos, classification_accuracy, 
            score_euc, score_cos
        ) = evaluate_model(device, model, criterion, val_loader, threshold_euc, threshold_cos)
        
        print(f'Epoch {epoch + 1}, Train Loss: {avg_epoch_loss}')
        print(f'Validation Loss:        {val_loss:.4f}')
        print(f'Validation Cls Acc:     {classification_accuracy:.4f}')
        print(f'Validation Pos Acc Euc: {same_accuracy_euc:.4f}')
        print(f'Validation Neg Acc Euc: {different_accuracy_euc:.4f}')
        print(f'Validation Pos Acc Cos: {same_class_accuracy_cos:.4f}')
        print(f'Validation Neg Acc Cos: {different_class_accuracy_cos:.4f}')
        print(f'Validation Score   Cos: {score_cos:.4f}')
        
        writter.add_scalar('Threshold/Euc', threshold_euc, epoch)
        writter.add_scalar('Threshold/Cos', threshold_cos, epoch)
        writter.add_scalar('Loss/Train', avg_epoch_loss, epoch)
        writter.add_scalar('Loss/Validation', val_loss, epoch)
        writter.add_scalar('Accuracy/Validation/Classification', classification_accuracy, epoch)
        writter.add_scalar('Accuracy/Validation/Same Class Euclid', same_accuracy_euc, epoch)
        writter.add_scalar('Accuracy/Validation/Different Class Euclid', different_accuracy_euc, epoch)
        writter.add_scalar('Accuracy/Validation/Same Class Cosine', same_class_accuracy_cos, epoch)
        writter.add_scalar('Accuracy/Validation/Different Class Cosine', different_class_accuracy_cos, epoch)
        writter.add_scalar('Score/Validation Euclid', score_euc, epoch)
        writter.add_scalar('Score/Validation Cosine', score_cos, epoch)


        if score_cos > best_score_cos:
            best_score_cos = score_cos
            torch.save(model.state_dict(), weight_path+'_quantized_best.pth')
            print(f'new best model saved into: {weight_path}_quantized_best.pth with acc={classification_accuracy:.4f}, score={score_cos:.4f}')
        
        scheduler.step(val_loss)
    
    writter.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="export models to onnx, half onnx. quantized onnx")
    parser.add_argument('--weight_path', type=str, help='full path and name for detect model, and only prefix for classification', default='./weight/cad_hybrid')
    parser.add_argument('--mode', type=str, help='none for normal export, half to export as fp16, quantization to export an int8 model')
    parser.add_argument('--init', action='store_true', help='train from default weight')
    parser.add_argument('--weight_path', type=str, help='where to save the trained weights', default='./weights/cad_rep')
    parser.add_argument('--threshold_path', type=str, default='./weights/threshold.npz')
    parser.add_argument('--data', type=str, default='cropped_images')
    parser.add_argument('--num_epochs', type=int, default=100)
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--lr', type=float, default=0.01, help='init learning rate, 0.01 for SGD')
    parser.add_argument('--margin', type=float, default=1.0)
    args = parser.parse_args()

    class_to_idx_path = './weights/class_map.json'
    class_to_idx = load_class_mapping(class_to_idx_path)
    idx_to_class = {idx: cls_name for cls_name, idx in class_to_idx.items()}
    num_classes = len(class_to_idx)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    weight_path = args.weight_path
    mode = args.mode
    init = args.init
    weight_path = args.weight_path
    threshold_path = args.threshold_path
    data = args.data
    num_epochs = args.num_epochs
    batch_size = args.batch_size
    learning_rate = args.lr
    margin = args.margin
    
    model = get_student_model(num_classes=len(idx_to_class), 
                                    dropout_p=0, 
                                    init=False, 
                                    update=False, 
                                    weight_path=weight_path, 
                                    cuda=True if torch.cuda.is_available() else False).to(device)
    

    replace_relu6_with_relu(model)
    model.eval() 

    fuse_config = generate_fusion_config(model.features)
    
    # Apply the fusion
    model_fused = torch.quantization.fuse_modules(model, fuse_config)
    
    # Set the quantization backend
    # torch.backends.quantized.engine = 'fbgemm'
    torch.backends.quantized.engine = 'qnnpack'  # Use 'qnnpack' for ARM architectures, especially Apple M1

    # Quantization aware training preparation
    model_fused.qconfig = torch.quantization.get_default_qconfig('qnnpack')
    torch.quantization.prepare(model_fused, inplace=True)

    train_loader, num_class = get_data_loaders(root_dir=data, mode='train', batch_size=256)
    val_loader, _ = get_data_loaders(root_dir=data, mode='val', batch_size=256)

    train_quantized(device, init, margin, learning_rate, num_class, num_epochs, train_loader, val_loader, weight_path, threshold_path)

    torch.quantization.convert(model_fused, inplace=True)

    # Save the quantized model
    torch.save(model_fused.state_dict(), f'{weight_path}_quantized.pth')

    # Optional: Export to ONNX
    dummy_input = torch.randn(1, 1, 32, 32)  #
    torch.onnx.export(model_fused, dummy_input, f'{weight_path}_quantized.onnx', input_names=['input'], output_names=['output'])
